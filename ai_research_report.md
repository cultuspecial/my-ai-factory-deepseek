# AI 简报 (2026-01-30)

### RedSage: A Cybersecurity Generalist LLM
📄 本文提出RedSage，一个开源的、可本地部署的网络安全大语言模型，通过构建11.8B token的网络安全领域持续预训练数据集和模拟专家工作流程生成的26.6万轮次对话样本进行微调，解决了现有方案在隐私风险与领域适应性之间的不足。
🔗 http://arxiv.org/abs/2601.22159v1

### Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts
📄 本文提出HALO框架，通过改进的线性注意力蒸馏方法，在仅需少量训练数据（约1B token）的情况下，将预训练的Transformer高效转化为混合注意力架构，显著提升超长上下文建模的性能与推理效率。
🔗 http://arxiv.org/abs/2601.22156v1

### Exploring Reasoning Reward Model for Agents
📄 本文提出了一种多维度推理奖励模型（Agent-RRM），通过提供结构化反馈（包括显式推理轨迹、针对性缺陷指正和整体过程评分）来优化智能体强化学习，解决了传统稀疏结果奖励无法评估中间推理质量的问题。
🔗 http://arxiv.org/abs/2601.22154v1
